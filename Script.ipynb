{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Simulator:\n",
    "    def __init__(self, board_dim, predators=[], preys=[]):\n",
    "        self.board = np.zeros(board_dim, dtype=int)\n",
    "\n",
    "        for p in predators:\n",
    "            self.board[p.coords[0]][p.coords[1]] = 2\n",
    "            p.board_dim = board_dim\n",
    "\n",
    "        for p in preys:\n",
    "            self.board[p.coords[0]][p.coords[1]] = 1\n",
    "            p.board_dim = board_dim\n",
    "\n",
    "        self.predators = predators\n",
    "        self.preys = preys\n",
    "        self.frames = [self.board.tolist()]\n",
    "\n",
    "    def save_history(self, filepath):\n",
    "        with open(filepath, \"w\") as f:\n",
    "            json.dump(self.frames, f)\n",
    "\n",
    "    def simulate(self):\n",
    "        for _ in range(5):\n",
    "            for pred in self.predators:\n",
    "                info = pred.take_action(pred.decide_action(self.board))\n",
    "\n",
    "                self.board[info[0][0]][info[0][1]] = 0\n",
    "                self.board[info[1][0]][info[1][1]] = 2\n",
    "\n",
    "            self.frames.append(self.board.tolist())\n",
    "            self.save_history(\"history.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, coords):\n",
    "        self.coords = coords\n",
    "\n",
    "        self.actions = {\n",
    "            \"up\": [-1, 0],\n",
    "            \"down\": [1, 0],\n",
    "            \"left\": [0, -1],\n",
    "            \"right\": [0, 1]\n",
    "        }\n",
    "\n",
    "        self.q_table = {\n",
    "            \"\".join([\"0\"]*24): [0,0,0,0]\n",
    "        }\n",
    "\n",
    "    def take_action(self, action):\n",
    "        \"\"\"\n",
    "        Take an action (up, down, left, right), update and return the new state\n",
    "        \"\"\"\n",
    "        row = (self.coords[0] + self.actions[action][0]) % self.board_dim[0]\n",
    "        col = (self.coords[1] + self.actions[action][1]) % self.board_dim[1]\n",
    "\n",
    "        if row < 0:\n",
    "            row += self.board_dim[0]\n",
    "        if col < 0:\n",
    "            col += self.board_dim[1]\n",
    "\n",
    "        old_coords = self.coords\n",
    "\n",
    "        self.coords = [row, col]\n",
    "\n",
    "\n",
    "        ### Update Q-table\n",
    "\n",
    "\n",
    "        return old_coords, self.coords\n",
    "    \n",
    "    def encode_state(self, state, n):\n",
    "        splitter = int((n*2+1)**2/2)\n",
    "        return \"\".join([str(el) for el in np.concatenate([state.flatten()[:splitter], state.flatten()[splitter+1:]]).flatten()])\n",
    "    \n",
    "    def decide_action(self, board):\n",
    "        state = self.encode_state(self.get_state(board)) \n",
    "        if state not in self.q_table:\n",
    "            self.q_table[state] = [0,0,0,0]\n",
    "\n",
    "        state = self.q_table[state]\n",
    "\n",
    "        return list(self.actions.keys())[np.random.choice([i for i, v in enumerate(state) if v == max(state)])]\n",
    "\n",
    "\n",
    "\n",
    "class Predator(Agent):\n",
    "    def encode_state(self, state):\n",
    "        return super().encode_state(state, 2)\n",
    "    \n",
    "    def get_state(self, board):\n",
    "        row1 = (self.coords[0] - 2) % self.board_dim[0]\n",
    "        row2 = (self.coords[0] + 2) % self.board_dim[0]\n",
    "        col1 = (self.coords[1] - 2) % self.board_dim[1]\n",
    "        col2 = (self.coords[1] + 2) % self.board_dim[1]\n",
    "\n",
    "        row1 = max(row1, (row1+10)%10 )\n",
    "        row2 = max(row2, (row2+10)%10 )\n",
    "        col1 = max(col1, (col1+10)%10 )\n",
    "        col2 = max(col2, (col2+10)%10 )\n",
    "\n",
    "        if row1 > 5 and col1 > 5:\n",
    "            state = np.concatenate( [np.concatenate([board[row1:len(board), col1:len(board[0])], board[:row2+1, col1:len(board[0])]])  ,  \\\n",
    "                    np.concatenate([board[row1:len(board), :col2+1], board[:row2+1, :col2+1]])                ], axis=1 ) \n",
    "        elif row1 > 5:\n",
    "            state = np.concatenate([board[row1:len(board), col1:col2+1], board[:row2+1, col1:col2+1]]) \n",
    "        elif col1 > 5:\n",
    "            state = np.concatenate([board[row1:row2+1, col1:len(board[0])], board[row1:row2+1, :col2+1]], axis=1)\n",
    "        else:\n",
    "            state = board[row1:row2+1, col1:col2+1]\n",
    "\n",
    "        return state\n",
    "    \n",
    "\n",
    "class Prey(Agent):\n",
    "    def encode_state(self, state):\n",
    "        return super().encode_state(state, 1)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "board_dim = [10, 10]\n",
    "\n",
    "pred = Predator([5,5])\n",
    "p1 = Prey([1,1])\n",
    "p2 = Prey([2,2])\n",
    "p3 = Prey([5,8])\n",
    "\n",
    "s = Simulator(board_dim, [pred], [p1, p2, p3])\n",
    "\n",
    "s.simulate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
